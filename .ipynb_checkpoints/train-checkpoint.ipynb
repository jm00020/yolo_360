{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "from models import *\n",
    "from utils.utils import *\n",
    "from utils.datasets import *\n",
    "from utils.parse_config import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "image_folder = \"D:/Downloads/PyTorch-YOLOv3-master (2)/PyTorch-YOLOv3-master/data/sample\"\n",
    "batch_size = 16\n",
    "model_config_path = \"config/yolov3.cfg\"\n",
    "data_config_path = \"config/coco.data\"\n",
    "weights_path = \"weights/yolov3.weights\"\n",
    "class_path = \"D:/Downloads/PyTorch-YOLOv3-master (2)/PyTorch-YOLOv3-master/data/coco.names\"\n",
    "conf_thres = 0.8\n",
    "nms_thres = 0.4\n",
    "n_cpu = 10\n",
    "img_size = 416\n",
    "checkpoint_interval = 1\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "use_cuda = True\n",
    "\n",
    "cuda = torch.cuda.is_available() and use_cuda\n",
    "\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)\n",
    "\n",
    "classes = load_classes(class_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\torch\\nn\\_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "D:\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1, Batch 0/7329] [Losses: x 0.202459, y 0.182324, w 3.286720, h 3.416559, conf 17.702590, cls 0.690809, total 25.481461, recall: 0.25703, precision: 0.46870]\n",
      "[Epoch 0/1, Batch 1/7329] [Losses: x 0.227707, y 0.217287, w 3.316281, h 2.710403, conf 11.668760, cls 0.734055, total 18.874493, recall: 0.12766, precision: 0.08102]\n",
      "[Epoch 0/1, Batch 2/7329] [Losses: x 0.225957, y 0.221245, w 1.532523, h 2.194858, conf 4.368204, cls 0.762917, total 9.305704, recall: 0.26010, precision: 0.04230]\n",
      "[Epoch 0/1, Batch 3/7329] [Losses: x 0.215183, y 0.220739, w 1.776638, h 1.839410, conf 3.187920, cls 0.806366, total 8.046257, recall: 0.09579, precision: 0.00304]\n",
      "[Epoch 0/1, Batch 4/7329] [Losses: x 0.228808, y 0.229455, w 2.372138, h 1.988834, conf 2.769707, cls 0.804612, total 8.393555, recall: 0.07937, precision: 0.00267]\n",
      "[Epoch 0/1, Batch 5/7329] [Losses: x 0.239373, y 0.211166, w 1.597599, h 1.747833, conf 3.330034, cls 0.792105, total 7.918110, recall: 0.16550, precision: 0.00680]\n",
      "[Epoch 0/1, Batch 6/7329] [Losses: x 0.220413, y 0.249411, w 1.493836, h 1.838327, conf 2.435319, cls 0.805337, total 7.042643, recall: 0.09622, precision: 0.00319]\n",
      "[Epoch 0/1, Batch 7/7329] [Losses: x 0.237883, y 0.225716, w 1.482774, h 1.011121, conf 3.665811, cls 0.784938, total 7.408244, recall: 0.25098, precision: 0.00757]\n",
      "[Epoch 0/1, Batch 8/7329] [Losses: x 0.226678, y 0.235105, w 1.135711, h 1.269081, conf 2.154045, cls 0.797609, total 5.818230, recall: 0.15909, precision: 0.00658]\n",
      "[Epoch 0/1, Batch 9/7329] [Losses: x 0.233801, y 0.235342, w 1.336648, h 1.201102, conf 2.369215, cls 0.801520, total 6.177629, recall: 0.13821, precision: 0.00366]\n",
      "[Epoch 0/1, Batch 10/7329] [Losses: x 0.238449, y 0.237577, w 1.190692, h 1.368318, conf 2.390224, cls 0.796468, total 6.221729, recall: 0.20795, precision: 0.00414]\n",
      "[Epoch 0/1, Batch 11/7329] [Losses: x 0.238830, y 0.228667, w 1.267436, h 2.224739, conf 2.077737, cls 0.806444, total 6.843854, recall: 0.11905, precision: 0.00291]\n",
      "[Epoch 0/1, Batch 12/7329] [Losses: x 0.225262, y 0.221755, w 1.397354, h 1.145612, conf 2.137528, cls 0.798491, total 5.926003, recall: 0.17718, precision: 0.00325]\n",
      "[Epoch 0/1, Batch 13/7329] [Losses: x 0.217750, y 0.230503, w 1.272121, h 1.008522, conf 2.169206, cls 0.797955, total 5.696058, recall: 0.19324, precision: 0.00334]\n",
      "[Epoch 0/1, Batch 14/7329] [Losses: x 0.240093, y 0.231481, w 1.371988, h 1.323117, conf 1.943848, cls 0.801170, total 5.911696, recall: 0.13002, precision: 0.00722]\n",
      "[Epoch 0/1, Batch 15/7329] [Losses: x 0.239483, y 0.233164, w 1.290430, h 1.228279, conf 2.943208, cls 0.784671, total 6.719236, recall: 0.25069, precision: 0.00834]\n",
      "[Epoch 0/1, Batch 16/7329] [Losses: x 0.237817, y 0.229368, w 1.516940, h 1.012814, conf 2.329908, cls 0.804609, total 6.131456, recall: 0.10798, precision: 0.00238]\n",
      "[Epoch 0/1, Batch 17/7329] [Losses: x 0.243316, y 0.238241, w 1.209237, h 1.135288, conf 1.996061, cls 0.791018, total 5.613161, recall: 0.17241, precision: 0.00577]\n",
      "[Epoch 0/1, Batch 18/7329] [Losses: x 0.215826, y 0.221472, w 1.514747, h 1.725758, conf 2.027007, cls 0.782520, total 6.487329, recall: 0.21609, precision: 0.00836]\n",
      "[Epoch 0/1, Batch 19/7329] [Losses: x 0.206671, y 0.221779, w 1.343640, h 1.341808, conf 1.904786, cls 0.809470, total 5.828154, recall: 0.06944, precision: 0.00222]\n",
      "[Epoch 0/1, Batch 20/7329] [Losses: x 0.230965, y 0.243513, w 1.211844, h 1.387542, conf 2.289875, cls 0.784228, total 6.147967, recall: 0.15812, precision: 0.00526]\n",
      "[Epoch 0/1, Batch 21/7329] [Losses: x 0.220749, y 0.205036, w 1.744266, h 1.447456, conf 1.739784, cls 0.753940, total 6.111231, recall: 0.30033, precision: 0.00954]\n",
      "[Epoch 0/1, Batch 22/7329] [Losses: x 0.225197, y 0.210365, w 1.571972, h 1.234257, conf 2.363839, cls 0.764355, total 6.369985, recall: 0.27389, precision: 0.00992]\n",
      "[Epoch 0/1, Batch 23/7329] [Losses: x 0.234157, y 0.219021, w 1.215160, h 1.233125, conf 2.708014, cls 0.783963, total 6.393440, recall: 0.16230, precision: 0.00909]\n",
      "[Epoch 0/1, Batch 24/7329] [Losses: x 0.220159, y 0.214962, w 1.327430, h 1.172860, conf 2.026924, cls 0.775911, total 5.738246, recall: 0.20035, precision: 0.00993]\n",
      "[Epoch 0/1, Batch 25/7329] [Losses: x 0.233203, y 0.226553, w 1.298613, h 1.158811, conf 2.178782, cls 0.761903, total 5.857864, recall: 0.19094, precision: 0.00566]\n",
      "[Epoch 0/1, Batch 26/7329] [Losses: x 0.236911, y 0.234979, w 1.134408, h 0.950128, conf 1.941446, cls 0.783463, total 5.281336, recall: 0.18830, precision: 0.00655]\n",
      "[Epoch 0/1, Batch 27/7329] [Losses: x 0.234480, y 0.220331, w 1.295071, h 1.162541, conf 1.979866, cls 0.751417, total 5.643704, recall: 0.28409, precision: 0.00722]\n",
      "[Epoch 0/1, Batch 28/7329] [Losses: x 0.248025, y 0.235244, w 1.209983, h 1.051613, conf 2.016859, cls 0.773827, total 5.535552, recall: 0.20000, precision: 0.00610]\n",
      "[Epoch 0/1, Batch 29/7329] [Losses: x 0.235593, y 0.221098, w 1.197298, h 0.783507, conf 1.743028, cls 0.762660, total 4.943184, recall: 0.25417, precision: 0.01057]\n",
      "[Epoch 0/1, Batch 30/7329] [Losses: x 0.220998, y 0.253535, w 1.466744, h 1.273833, conf 1.823208, cls 0.773666, total 5.811984, recall: 0.20904, precision: 0.00436]\n",
      "[Epoch 0/1, Batch 31/7329] [Losses: x 0.220924, y 0.231521, w 1.032803, h 1.005484, conf 2.044304, cls 0.779720, total 5.314756, recall: 0.15456, precision: 0.00725]\n",
      "[Epoch 0/1, Batch 32/7329] [Losses: x 0.232042, y 0.205447, w 1.299404, h 0.843357, conf 1.760538, cls 0.764120, total 5.104908, recall: 0.24444, precision: 0.00890]\n",
      "[Epoch 0/1, Batch 33/7329] [Losses: x 0.227483, y 0.245680, w 1.470838, h 1.126585, conf 1.911117, cls 0.749333, total 5.731036, recall: 0.29048, precision: 0.02259]\n",
      "[Epoch 0/1, Batch 34/7329] [Losses: x 0.227996, y 0.242811, w 1.063329, h 0.989867, conf 1.657993, cls 0.768079, total 4.950076, recall: 0.22319, precision: 0.01222]\n",
      "[Epoch 0/1, Batch 35/7329] [Losses: x 0.224435, y 0.194458, w 1.548711, h 1.693346, conf 1.782055, cls 0.779975, total 6.222980, recall: 0.13390, precision: 0.00466]\n",
      "[Epoch 0/1, Batch 36/7329] [Losses: x 0.231491, y 0.230998, w 1.065158, h 0.959357, conf 1.687081, cls 0.767321, total 4.941406, recall: 0.18000, precision: 0.00763]\n",
      "[Epoch 0/1, Batch 37/7329] [Losses: x 0.217859, y 0.222347, w 1.035943, h 0.880751, conf 1.946246, cls 0.758208, total 5.061354, recall: 0.24324, precision: 0.00625]\n",
      "[Epoch 0/1, Batch 38/7329] [Losses: x 0.228306, y 0.236045, w 1.227443, h 1.214014, conf 2.106638, cls 0.787025, total 5.799471, recall: 0.11957, precision: 0.00336]\n",
      "[Epoch 0/1, Batch 39/7329] [Losses: x 0.219617, y 0.235488, w 1.755942, h 0.995803, conf 1.684478, cls 0.793005, total 5.684333, recall: 0.10653, precision: 0.00274]\n",
      "[Epoch 0/1, Batch 40/7329] [Losses: x 0.214335, y 0.219974, w 1.215591, h 1.048562, conf 1.632883, cls 0.752446, total 5.083792, recall: 0.27937, precision: 0.00994]\n",
      "[Epoch 0/1, Batch 41/7329] [Losses: x 0.222939, y 0.229926, w 1.370612, h 0.787047, conf 1.809721, cls 0.777567, total 5.197812, recall: 0.20062, precision: 0.00801]\n",
      "[Epoch 0/1, Batch 42/7329] [Losses: x 0.248255, y 0.222718, w 1.338141, h 0.916390, conf 1.700361, cls 0.775683, total 5.201550, recall: 0.17125, precision: 0.00592]\n",
      "[Epoch 0/1, Batch 43/7329] [Losses: x 0.216951, y 0.230484, w 1.072673, h 1.050036, conf 1.618851, cls 0.765372, total 4.954367, recall: 0.20968, precision: 0.00558]\n",
      "[Epoch 0/1, Batch 44/7329] [Losses: x 0.252460, y 0.223270, w 1.128279, h 0.849380, conf 1.822796, cls 0.727856, total 5.004041, recall: 0.36842, precision: 0.01056]\n",
      "[Epoch 0/1, Batch 45/7329] [Losses: x 0.235637, y 0.203564, w 1.144353, h 0.992891, conf 1.677656, cls 0.765945, total 5.020046, recall: 0.22342, precision: 0.01056]\n",
      "[Epoch 0/1, Batch 46/7329] [Losses: x 0.210974, y 0.228099, w 1.379093, h 1.025626, conf 1.713661, cls 0.756457, total 5.313910, recall: 0.25725, precision: 0.01212]\n",
      "[Epoch 0/1, Batch 47/7329] [Losses: x 0.244183, y 0.234730, w 1.106003, h 0.996796, conf 1.738275, cls 0.750134, total 5.070121, recall: 0.25526, precision: 0.00856]\n",
      "[Epoch 0/1, Batch 48/7329] [Losses: x 0.229775, y 0.208013, w 0.938581, h 0.739747, conf 1.538294, cls 0.756203, total 4.410612, recall: 0.25432, precision: 0.00959]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/1, Batch 49/7329] [Losses: x 0.239380, y 0.239375, w 1.225268, h 1.001329, conf 1.593187, cls 0.762611, total 5.061149, recall: 0.19780, precision: 0.00567]\n",
      "[Epoch 0/1, Batch 50/7329] [Losses: x 0.236515, y 0.231728, w 1.356920, h 0.920322, conf 1.635719, cls 0.727631, total 5.108835, recall: 0.36772, precision: 0.01440]\n",
      "[Epoch 0/1, Batch 51/7329] [Losses: x 0.220444, y 0.253072, w 1.270615, h 1.017671, conf 1.554031, cls 0.745420, total 5.061254, recall: 0.27564, precision: 0.01300]\n",
      "[Epoch 0/1, Batch 52/7329] [Losses: x 0.233841, y 0.233474, w 0.877606, h 0.885007, conf 1.808187, cls 0.754025, total 4.792139, recall: 0.27407, precision: 0.01021]\n",
      "[Epoch 0/1, Batch 53/7329] [Losses: x 0.197140, y 0.218435, w 1.446171, h 1.239277, conf 2.437690, cls 0.771548, total 6.310261, recall: 0.13559, precision: 0.00410]\n",
      "[Epoch 0/1, Batch 54/7329] [Losses: x 0.228877, y 0.211713, w 1.095710, h 0.956269, conf 1.572658, cls 0.743180, total 4.808406, recall: 0.30328, precision: 0.01162]\n",
      "[Epoch 0/1, Batch 55/7329] [Losses: x 0.232264, y 0.248068, w 1.158743, h 1.182590, conf 1.777763, cls 0.770314, total 5.369742, recall: 0.16319, precision: 0.00427]\n",
      "[Epoch 0/1, Batch 56/7329] [Losses: x 0.216363, y 0.230835, w 1.152731, h 1.104854, conf 1.816499, cls 0.761423, total 5.282704, recall: 0.20110, precision: 0.00595]\n",
      "[Epoch 0/1, Batch 57/7329] [Losses: x 0.193046, y 0.224959, w 1.271094, h 1.067926, conf 1.927328, cls 0.743869, total 5.428222, recall: 0.26521, precision: 0.00946]\n",
      "[Epoch 0/1, Batch 58/7329] [Losses: x 0.209120, y 0.203778, w 1.316764, h 1.293555, conf 1.648873, cls 0.773572, total 5.445661, recall: 0.15517, precision: 0.00471]\n",
      "[Epoch 0/1, Batch 59/7329] [Losses: x 0.201347, y 0.240398, w 1.015451, h 0.858378, conf 2.038986, cls 0.795293, total 5.149853, recall: 0.10653, precision: 0.00291]\n",
      "[Epoch 0/1, Batch 60/7329] [Losses: x 0.218944, y 0.217502, w 0.834711, h 0.839188, conf 1.712523, cls 0.750866, total 4.573733, recall: 0.22321, precision: 0.00665]\n",
      "[Epoch 0/1, Batch 61/7329] [Losses: x 0.257072, y 0.259749, w 0.986074, h 0.834265, conf 1.580721, cls 0.763486, total 4.681367, recall: 0.19000, precision: 0.00610]\n",
      "[Epoch 0/1, Batch 62/7329] [Losses: x 0.227601, y 0.219167, w 0.924216, h 0.796252, conf 1.748316, cls 0.733164, total 4.648717, recall: 0.31832, precision: 0.01052]\n",
      "[Epoch 0/1, Batch 63/7329] [Losses: x 0.226637, y 0.212048, w 1.446713, h 0.776408, conf 1.605591, cls 0.728271, total 4.995668, recall: 0.27066, precision: 0.00966]\n",
      "[Epoch 0/1, Batch 64/7329] [Losses: x 0.217715, y 0.231834, w 0.998489, h 0.756514, conf 1.590775, cls 0.746089, total 4.541418, recall: 0.26007, precision: 0.00976]\n",
      "[Epoch 0/1, Batch 65/7329] [Losses: x 0.202103, y 0.259277, w 1.102007, h 0.928928, conf 3.002352, cls 0.777295, total 6.271963, recall: 0.18213, precision: 0.00702]\n",
      "[Epoch 0/1, Batch 66/7329] [Losses: x 0.216090, y 0.213137, w 1.386426, h 1.070970, conf 1.696570, cls 0.746358, total 5.329551, recall: 0.23973, precision: 0.00929]\n",
      "[Epoch 0/1, Batch 67/7329] [Losses: x 0.236961, y 0.193945, w 1.082654, h 0.980266, conf 1.837911, cls 0.780896, total 5.112633, recall: 0.13514, precision: 0.00303]\n",
      "[Epoch 0/1, Batch 68/7329] [Losses: x 0.233934, y 0.232683, w 0.974885, h 0.887061, conf 1.774112, cls 0.764893, total 4.867568, recall: 0.19850, precision: 0.00471]\n",
      "[Epoch 0/1, Batch 69/7329] [Losses: x 0.252145, y 0.244813, w 1.106683, h 1.248227, conf 2.495488, cls 0.782924, total 6.130280, recall: 0.11957, precision: 0.00323]\n",
      "[Epoch 0/1, Batch 70/7329] [Losses: x 0.208565, y 0.227606, w 1.268380, h 1.206438, conf 1.660167, cls 0.715814, total 5.286969, recall: 0.39571, precision: 0.01683]\n",
      "[Epoch 0/1, Batch 71/7329] [Losses: x 0.222720, y 0.203548, w 0.800286, h 0.792010, conf 2.405518, cls 0.758563, total 5.182645, recall: 0.19667, precision: 0.00643]\n",
      "[Epoch 0/1, Batch 72/7329] [Losses: x 0.223625, y 0.214135, w 1.166481, h 0.880344, conf 1.969757, cls 0.737680, total 5.192022, recall: 0.36198, precision: 0.01166]\n",
      "[Epoch 0/1, Batch 73/7329] [Losses: x 0.202593, y 0.216264, w 1.261141, h 1.155593, conf 1.927419, cls 0.781225, total 5.544235, recall: 0.15625, precision: 0.00334]\n",
      "[Epoch 0/1, Batch 74/7329] [Losses: x 0.223123, y 0.254459, w 1.168523, h 1.298580, conf 1.763958, cls 0.758593, total 5.467237, recall: 0.21569, precision: 0.00527]\n",
      "[Epoch 0/1, Batch 75/7329] [Losses: x 0.197285, y 0.214545, w 1.004137, h 0.867461, conf 1.726375, cls 0.756957, total 4.766760, recall: 0.23509, precision: 0.00486]\n",
      "[Epoch 0/1, Batch 76/7329] [Losses: x 0.198012, y 0.190998, w 0.924651, h 0.736628, conf 1.779917, cls 0.774103, total 4.604309, recall: 0.18265, precision: 0.00510]\n",
      "[Epoch 0/1, Batch 77/7329] [Losses: x 0.259007, y 0.196745, w 1.104809, h 1.012973, conf 1.858900, cls 0.773973, total 5.206407, recall: 0.19417, precision: 0.00442]\n",
      "[Epoch 0/1, Batch 78/7329] [Losses: x 0.248547, y 0.212198, w 1.322222, h 1.065401, conf 1.733628, cls 0.767360, total 5.349357, recall: 0.20088, precision: 0.00805]\n",
      "[Epoch 0/1, Batch 79/7329] [Losses: x 0.215337, y 0.196205, w 0.910398, h 0.869096, conf 1.616049, cls 0.770099, total 4.577184, recall: 0.16949, precision: 0.00572]\n",
      "[Epoch 0/1, Batch 80/7329] [Losses: x 0.227723, y 0.237317, w 1.128909, h 1.637592, conf 1.775054, cls 0.758472, total 5.765065, recall: 0.13930, precision: 0.00558]\n",
      "[Epoch 0/1, Batch 81/7329] [Losses: x 0.229644, y 0.192648, w 1.432298, h 1.152752, conf 1.697320, cls 0.776549, total 5.481212, recall: 0.15705, precision: 0.00377]\n",
      "[Epoch 0/1, Batch 82/7329] [Losses: x 0.213872, y 0.221511, w 1.197510, h 0.800159, conf 1.887521, cls 0.744713, total 5.065288, recall: 0.26566, precision: 0.01975]\n",
      "[Epoch 0/1, Batch 83/7329] [Losses: x 0.218168, y 0.221062, w 1.072208, h 1.071898, conf 1.982329, cls 0.750909, total 5.316574, recall: 0.21739, precision: 0.00968]\n",
      "[Epoch 0/1, Batch 84/7329] [Losses: x 0.257329, y 0.223998, w 1.032888, h 1.001220, conf 1.601530, cls 0.757788, total 4.874753, recall: 0.21849, precision: 0.00685]\n",
      "[Epoch 0/1, Batch 85/7329] [Losses: x 0.219314, y 0.207876, w 0.872122, h 0.830790, conf 1.787851, cls 0.773841, total 4.691793, recall: 0.18545, precision: 0.00584]\n",
      "[Epoch 0/1, Batch 86/7329] [Losses: x 0.246242, y 0.193699, w 1.395128, h 0.972566, conf 1.521021, cls 0.750852, total 5.079508, recall: 0.25117, precision: 0.00958]\n",
      "[Epoch 0/1, Batch 87/7329] [Losses: x 0.273844, y 0.227954, w 1.250195, h 0.875115, conf 1.857343, cls 0.801641, total 5.286092, recall: 0.05350, precision: 0.00133]\n",
      "[Epoch 0/1, Batch 88/7329] [Losses: x 0.220573, y 0.195426, w 0.978307, h 0.737429, conf 1.546023, cls 0.762553, total 4.440310, recall: 0.23102, precision: 0.00881]\n",
      "[Epoch 0/1, Batch 89/7329] [Losses: x 0.223728, y 0.213895, w 1.268409, h 1.247863, conf 1.832147, cls 0.743186, total 5.529228, recall: 0.27778, precision: 0.01133]\n",
      "[Epoch 0/1, Batch 90/7329] [Losses: x 0.259369, y 0.223614, w 1.236924, h 1.070532, conf 1.551469, cls 0.755920, total 5.097828, recall: 0.19142, precision: 0.00441]\n"
     ]
    }
   ],
   "source": [
    "data_config = parse_data_config(data_config_path)\n",
    "train_path = data_config[\"train\"]\n",
    "\n",
    "hyperparams = parse_model_config(model_config_path)[0]\n",
    "learning_rate = float(hyperparams[\"learning_rate\"])\n",
    "momentum = float(hyperparams[\"momentum\"])\n",
    "decay = float(hyperparams[\"decay\"])\n",
    "burn_in = int(hyperparams[\"burn_in\"])\n",
    "\n",
    "model = Darknet(model_config_path)\n",
    "model.load_weights(weights_path)\n",
    "# model.apply(weights_init_normal)\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "model.train()\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    ListDataset(train_path), batch_size, shuffle=False, num_workers=n_cpu\n",
    ")\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_i, (_, imgs, targets) in enumerate(dataloader):\n",
    "        imgs = Variable(imgs.type(Tensor))\n",
    "        targets = Variable(targets.type(Tensor), requires_grad=False)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = model(imgs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d, Batch %d/%d] [Losses: x %f, y %f, w %f, h %f, conf %f, cls %f, total %f, recall: %.5f, precision: %.5f]\"\n",
    "            % (\n",
    "                epoch,\n",
    "                epochs,\n",
    "                batch_i,\n",
    "                len(dataloader),\n",
    "                model.losses[\"x\"],\n",
    "                model.losses[\"y\"],\n",
    "                model.losses[\"w\"],\n",
    "                model.losses[\"h\"],\n",
    "                model.losses[\"conf\"],\n",
    "                model.losses[\"cls\"],\n",
    "                loss.item(),\n",
    "                model.losses[\"recall\"],\n",
    "                model.losses[\"precision\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        model.seen += imgs.size(0)\n",
    "\n",
    "    if epoch % checkpoint_interval == 0:\n",
    "        model.save_weights(\"%s/%d.weights\" % (checkpoint_dir, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
